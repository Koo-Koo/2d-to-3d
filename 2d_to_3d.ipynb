{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2d video to 3D\n",
    "\n",
    "This code makes .blend file from single video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2d Pose Estimation using Openpose\n",
    " - make images from video\n",
    " - 2d pose estimation by openpose\n",
    " - target video should be at '/openpose/sample_videos'\n",
    " - images create at  '/openpose/sample_images'\n",
    " - after 2d pose estimation json files create at '/openpose/sample_jsons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('openpose')\n",
    "!bash video_to_images.sh 24\n",
    "!bash 2d_estimation.sh\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Ground Position for Estimation\n",
    "- click 'left top','left bottom','right bottom','right bottom' in order\n",
    "- writes 'points' file at directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper button.btn.btn-default,\n",
    ".output_wrapper .ui-dialog-titlebar {\n",
    "  display: none;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl \n",
    "import numpy as np\n",
    "import matplotlib.lines as mlines\n",
    "import ipywidgets as wdg\n",
    "from IPython.display import display\n",
    "\n",
    "points = []\n",
    "prev = []\n",
    "cnt = 0\n",
    "\n",
    "a = plt.imread(\"sample.png\")\n",
    "fig = plt.figure()\n",
    "plt.imshow(a)\n",
    "\n",
    "def write():\n",
    "    global points\n",
    "    f = open(\"points\",'w+')\n",
    "    tmp = [str(x)+\" \"+str(y) for (x,y) in points]\n",
    "    f.write(\"\\n\".join(tmp))\n",
    "    f.close()\n",
    "\n",
    "def onclick(event):\n",
    "    global cnt,points,prev,msg\n",
    "    if cnt == 4:\n",
    "        return\n",
    "    x = float(event.xdata)\n",
    "    y = float(event.ydata)\n",
    "    points.append([x,y])\n",
    "    cnt += 1\n",
    "    plt.scatter(x,y,s=10,c='white')\n",
    "    if cnt>1:\n",
    "            now = [x,y]\n",
    "            line = plt.Polygon([prev,now], closed=None, fill=None, edgecolor='w')\n",
    "            plt.gca().add_line(line)\n",
    "            if cnt == 4:\n",
    "                line = plt.Polygon([now,points[0]], closed=None, fill=None, edgecolor='w')\n",
    "                area = plt.Polygon(points,closed=True,fill=True)\n",
    "                plt.gca().add_line(line)\n",
    "                plt.gca().add_line(area)\n",
    "                write()\n",
    "    prev = [x,y]\n",
    "    \n",
    "ka = fig.canvas.mpl_connect('button_press_event',onclick)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Calibration\n",
    "- creates ground position information\n",
    "- you need to enter ratio of the ground (default value: width=3 height=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# width height ratio\n",
    "! python calibration.py 3 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d Pose Estimation Using HMR\n",
    "- you need to enter number of people to estimate (default value: 1)\n",
    "- after 3d pose estimation it creates csv files at '/hmr/output/csv', 'hmr/output/csv_joined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bash hmr/mong_3dpose_estimate.sh 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make .bvh file Using Blender\n",
    "- you need to enter number of people to estimate (default value: 1)\n",
    "- you need to enter the name of bvh file\n",
    "- output files at 'hmr/output/bvh_animation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- [number of people] [output filename]\n",
    "blender --background hmr/csv_to_bvh.blend -noaudio -P hmr/mong_csv_to_bvh.py -- 1 squash1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make .blend file using Blender and Makehuman Model\n",
    "- you need to enter bvh filename, frame number, number of people \n",
    "- output .blend files at current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- [file_name] [frame_num] [people_num]\n",
    "blender --background --enable-autoexec --python render.py squash1 100 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor-gpu-py27",
   "language": "python",
   "name": "tensorflow-gpu-py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
